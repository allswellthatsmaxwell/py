{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip setuptools wheel\n",
    "\n",
    "# %pip install openai openai-whisper soundfile plotnine pyaudio sounddevice langchain\n",
    "## need `sudo apt install portaudio19-dev alsa-utils ffmpeg` for pyaudio/whisper\n",
    "\n",
    "# We need extra steps outside of code to make audio work in WSL2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AUDIO_DIR = \"/mnt/c/Users/allsw/OneDrive/Documents/Sound Recordings\"\n",
    "LOGS_DIR = \"/mnt/c/Users/allsw/projects/svl/logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mson/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "import whisper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import svl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriber = svl.Transcriber(whisper_model=model, audio_dir=AUDIO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I woke up at 1048 and I went to sleep around 2.45 a.m.\n"
     ]
    }
   ],
   "source": [
    "transcript = transcriber.transcribe('sleep1')\n",
    "print(transcript['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = svl.LogFilesFinder(transcript['text'], LOGS_DIR, llm).recommended_files # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wake_up_for_the_day.csv, hours_slept_last_night.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "Maybe it's useful to have two separate prompt streams that are getting history and context added to them: one for taking in the voice transcript and deciding what the commands to execute are, and one that takes those commands and executes them on the logs. Call the first one CommandBuilder and the second one CommandExecutor. This could make it easier to keep the different kinds of context organized. The context for CommandBuilder is the user's attempts to log things, and the Executor is the backend's attempts to modify the logs based on those commands.  \n",
    "\n",
    "CommandExecutor is an interesting idea - previously I was thinking I'd define fixed functions myself to do these operations on the log file. And that's probably still the correct idea. But, like, you could also give it the user's logs in JSON and then tell it to make the add. This scales poorly with the number of logs a user has, obviously. If we kept each log category in a separate file, and only give the contents of the relevant file as prompt context, that's a lot more tractable.\n",
    "\n",
    "And since logging something means adding one line to the bottom of a csv, you don't need to give the whole thing to the prompt! Just enough lines that it knows the format! Ahaaaaaa!!! Let's do this :D :D D:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
