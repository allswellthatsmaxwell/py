{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip setuptools wheel\n",
    "\n",
    "# %pip install openai openai-whisper soundfile plotnine assemblyai langchain\n",
    "## need `sudo apt install portaudio19-dev alsa-utils ffmpeg` for pyaudio/whisper\n",
    "# We need extra steps outside of code to make audio work in WSL2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = \"/mnt/c/Users/allsw/projects/structured-voice-logging\"\n",
    "AUDIO_DIR = f\"{PROJECT_DIR}/test_recordings\"\n",
    "LOGS_DIR = \"{PROJECT_DIR}/logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"ASSEMBLY_AI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import openai\n",
    "import whisper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import assemblyai\n",
    "\n",
    "import svl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriber = svl.Transcriber(audio_dir=AUDIO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_fpath = transcriber.get_file_substring_match('sleep1')\n",
    "transcript = transcriber.transcribe(audio_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I woke up at 10:40 a.m. And I went to sleep around 245 a.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = transcriber._upload(audio_fpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = transcriber._transcribe_upload(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'rhh7m2ssh0-e261-4ad7-a71c-94c56ee19fa8',\n",
       " 'language_model': 'assemblyai_default',\n",
       " 'acoustic_model': 'assemblyai_default',\n",
       " 'language_code': 'en_us',\n",
       " 'status': 'queued',\n",
       " 'audio_url': 'https://cdn.assemblyai.com/upload/b2176603-809f-404f-b82d-5211d78aeca7',\n",
       " 'text': None,\n",
       " 'words': None,\n",
       " 'utterances': None,\n",
       " 'confidence': None,\n",
       " 'audio_duration': None,\n",
       " 'punctuate': True,\n",
       " 'format_text': True,\n",
       " 'dual_channel': None,\n",
       " 'webhook_url': None,\n",
       " 'webhook_status_code': None,\n",
       " 'webhook_auth': False,\n",
       " 'webhook_auth_header_name': None,\n",
       " 'speed_boost': False,\n",
       " 'auto_highlights_result': None,\n",
       " 'auto_highlights': False,\n",
       " 'audio_start_from': None,\n",
       " 'audio_end_at': None,\n",
       " 'word_boost': [],\n",
       " 'boost_param': None,\n",
       " 'filter_profanity': False,\n",
       " 'redact_pii': False,\n",
       " 'redact_pii_audio': False,\n",
       " 'redact_pii_audio_quality': None,\n",
       " 'redact_pii_policies': None,\n",
       " 'redact_pii_sub': None,\n",
       " 'speaker_labels': False,\n",
       " 'content_safety': False,\n",
       " 'iab_categories': False,\n",
       " 'content_safety_labels': {},\n",
       " 'iab_categories_result': {},\n",
       " 'language_detection': False,\n",
       " 'custom_spelling': None,\n",
       " 'cluster_id': None,\n",
       " 'throttled': None,\n",
       " 'auto_chapters': False,\n",
       " 'summarization': False,\n",
       " 'summary_type': None,\n",
       " 'summary_model': None,\n",
       " 'disfluencies': False,\n",
       " 'sentiment_analysis': False,\n",
       " 'sentiment_analysis_results': None,\n",
       " 'chapters': None,\n",
       " 'entity_detection': False,\n",
       " 'entities': None}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'rhh7pihe1y-a27d-4df8-803d-52568cf55a3d',\n",
       " 'language_model': 'assemblyai_default',\n",
       " 'acoustic_model': 'assemblyai_default',\n",
       " 'language_code': 'en_us',\n",
       " 'status': 'queued',\n",
       " 'audio_url': 'https://cdn.assemblyai.com/upload/b2176603-809f-404f-b82d-5211d78aeca7',\n",
       " 'text': None,\n",
       " 'words': None,\n",
       " 'utterances': None,\n",
       " 'confidence': None,\n",
       " 'audio_duration': None,\n",
       " 'punctuate': True,\n",
       " 'format_text': True,\n",
       " 'dual_channel': None,\n",
       " 'webhook_url': None,\n",
       " 'webhook_status_code': None,\n",
       " 'webhook_auth': False,\n",
       " 'webhook_auth_header_name': None,\n",
       " 'speed_boost': False,\n",
       " 'auto_highlights_result': None,\n",
       " 'auto_highlights': False,\n",
       " 'audio_start_from': None,\n",
       " 'audio_end_at': None,\n",
       " 'word_boost': [],\n",
       " 'boost_param': None,\n",
       " 'filter_profanity': False,\n",
       " 'redact_pii': False,\n",
       " 'redact_pii_audio': False,\n",
       " 'redact_pii_audio_quality': None,\n",
       " 'redact_pii_policies': None,\n",
       " 'redact_pii_sub': None,\n",
       " 'speaker_labels': False,\n",
       " 'content_safety': False,\n",
       " 'iab_categories': False,\n",
       " 'content_safety_labels': {},\n",
       " 'iab_categories_result': {},\n",
       " 'language_detection': False,\n",
       " 'custom_spelling': None,\n",
       " 'cluster_id': None,\n",
       " 'throttled': None,\n",
       " 'auto_chapters': False,\n",
       " 'summarization': False,\n",
       " 'summary_type': None,\n",
       " 'summary_model': None,\n",
       " 'disfluencies': False,\n",
       " 'sentiment_analysis': False,\n",
       " 'sentiment_analysis_results': None,\n",
       " 'chapters': None,\n",
       " 'entity_detection': False,\n",
       " 'entities': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = svl.LogFilesFinder(transcript['text'], LOGS_DIR, llm).recommended_files # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wake_up_for_the_day.csv, hours_slept_last_night.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_logger = svl.TranscriptLogger(transcript_text=transcript['text'], logs_dir=LOGS_DIR, files=files, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Instructions ##\n",
      "    Your objective is to write log entries for a user, based on an audio transcript.\n",
      "    The user who recorded the audio is trying to log something, or multiple somethings. It is also possible the transcript is not trying to log anything.\n",
      "    If it's trying to log something, write a log entry for each thing the user is trying to log.\n",
      "    I will give you a list of files that correspond to topics that can be logged to. Log the right thing to the right file.\n",
      "    \n",
      "## Output Structure ##\n",
      "    Output a JSON object where each key is a file name and each value is the log entry for that file.\n",
      "    If the user is not trying to log anything, output an empty JSON object.\n",
      "    \n",
      "## Relevant files, and samples of their contents ##\n",
      "    /mnt/c/Users/allsw/projects/svl/logs/wake_up_for_the_day.csv:\n",
      "\n",
      "    Date,Time,Day,Amount,Notes\n",
      "    Jul 11 2022,10:30:00,Mon,,\\\"\\\"\n",
      "    Jul 08 2022,11:00:00,Fri,,\\\"\\\"\n",
      "    Jul 06 2022,09:20:00,Wed,,\\\"\\\"\n",
      "\n",
      "    /mnt/c/Users/allsw/projects/svl/logs/hours_slept_last_night.csv:\n",
      "\n",
      "    Date,Time,Day,Amount,Notes\n",
      "    Jul 11 2022,23:43:33,Mon,9,\\\"\\\"\n",
      "    Jul 08 2022,19:45:52,Fri,8,\\\"\\\"\n",
      "    Jul 04 2022,08:33:41,Mon,6.5,\\\"\\\"\n",
      "\n",
      "\n",
      "### Transcript ###\n",
      "     I woke up at 1048 and I went to sleep around 2.45 a.m.\n",
      "    \n",
      "### Output ###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(transcript_logger._prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = transcript_logger.get_json_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wake_up_for_the_day.csv': 'Jul 11 2022,10:48:00,Mon,,\"\"', 'hours_slept_last_night.csv': 'Jul 11 2022,02:45:00,Mon,6.25,\"\"'}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(completion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "Maybe it's useful to have two separate prompt streams that are getting history and context added to them: one for taking in the voice transcript and deciding what the commands to execute are, and one that takes those commands and executes them on the logs. Call the first one CommandBuilder and the second one CommandExecutor. This could make it easier to keep the different kinds of context organized. The context for CommandBuilder is the user's attempts to log things, and the Executor is the backend's attempts to modify the logs based on those commands.  \n",
    "\n",
    "CommandExecutor is an interesting idea - previously I was thinking I'd define fixed functions myself to do these operations on the log file. And that's probably still the correct idea. But, like, you could also give it the user's logs in JSON and then tell it to make the add. This scales poorly with the number of logs a user has, obviously. If we kept each log category in a separate file, and only give the contents of the relevant file as prompt context, that's a lot more tractable.\n",
    "\n",
    "And since logging something means adding one line to the bottom of a csv, you don't need to give the whole thing to the prompt! Just enough lines that it knows the format! Ahaaaaaa!!! Let's do this :D :D D:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
